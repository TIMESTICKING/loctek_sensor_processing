{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Author Jiabao Li\n",
    "#\n",
    "# Created on Mon May 27 2024\n",
    "#\n",
    "# Copyright (c) 2024 Loctek\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from preprocess import make_dataset, scale_IR, make_dataset_ex\n",
    "import torch.optim as optim\n",
    "from model import *\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, distance_dataset, IR_dataset, ground_truth, filename_dataset):\n",
    "        self.IR_dataset = IR_dataset\n",
    "        self.distance_dataset = distance_dataset\n",
    "        self.ground_truth = ground_truth\n",
    "        self.filename_dataset = filename_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.IR_dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        IR_data = self.IR_dataset[idx]\n",
    "        distance_data = self.distance_dataset[idx]\n",
    "        label = self.ground_truth[idx]\n",
    "        # 将标签转换为one-hot编码\n",
    "        label_one_hot = torch.zeros(LABEL_NUM)\n",
    "        label_one_hot[label] = 1\n",
    "        return IR_data, distance_data, label_one_hot, self.filename_dataset[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_modle_str = 'high'\n",
    "g_modle_str = 'low'\n",
    "g_modle_extra_str = '1'\n",
    "\n",
    "# trainset, testset = make_dataset()\n",
    "trainset, testset = make_dataset_ex(g_modle_str)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = CustomDataset(*trainset)\n",
    "test_dataset = CustomDataset(*testset)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainset[2]\n",
    "# 计算每个类别出现的次数\n",
    "num_samples = len(labels)\n",
    "num_classes = max(labels) + 1  # 假设类别标签从0开始且连续\n",
    "class_counts = [labels.count(i) for i in range(num_classes)]\n",
    "\n",
    "# 计算每个类别的权重，使用类别频率的倒数\n",
    "weights = [num_samples / class_counts[i] if class_counts[i] > 0 else 0 for i in range(num_classes)]\n",
    "\n",
    "# 转换为Tensor\n",
    "weights_tensor = torch.tensor(weights).to(mydevice)\n",
    "print(weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 实例化网络\n",
    "net = MyMLP().to(mydevice)\n",
    "# net = MyCNN().to(mydevice)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "print(\"if gpu=\",torch.cuda.is_available())\n",
    "# 训练循环示例\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, (IR_data, distance_data, labels, _) in enumerate(train_dataloader, 0):\n",
    "        IR_data = IR_data.to(mydevice)\n",
    "        distance_data = distance_data.to(mydevice)\n",
    "        labels = labels.to(mydevice)\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = net(IR_data, distance_data)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新权重\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印统计信息\n",
    "        running_loss += loss.cpu().item()\n",
    "        if i % 20 == 19:  # 每10个批次打印一次\n",
    "            loss_mean = running_loss / 20\n",
    "            loss_history.append(loss_mean)\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {loss_mean:.3f}\")\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# 测试循环\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "filenames = []\n",
    "with torch.no_grad():\n",
    "    for i, (IR_data, distance_data, labels, filename) in enumerate(test_dataloader):\n",
    "        IR_data = IR_data.to(mydevice)\n",
    "        distance_data = distance_data.to(mydevice)\n",
    "\n",
    "        outputs = net(IR_data, distance_data)\n",
    "        outputs = outputs.cpu()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, gt = torch.max(labels.data, 1)\n",
    "        \n",
    "        true_labels.extend(gt.numpy())\n",
    "        predicted_labels.extend(predicted.numpy())\n",
    "        filenames += filename\n",
    "\n",
    "# 计算性能指标\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=1) # macro\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\\n\")\n",
    "\n",
    "# 计算每个类别的精确度和召回率\n",
    "precision_per_class = precision_score(true_labels, predicted_labels, average=None, zero_division=0)\n",
    "recall_per_class = recall_score(true_labels, predicted_labels, average=None, zero_division=0)\n",
    "\n",
    "# 打印结果\n",
    "print(\"labels are \", ['idle', 'sit', 'sit2stand', 'stand', 'stand2sit'])\n",
    "print(f\"Precision per class: {precision_per_class}\")\n",
    "print(f\"Recall per class: {recall_per_class}\\n\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "tmp_test_count = cm.sum()\n",
    "\n",
    "# 无人判断为有人\n",
    "idle_err_count  = (cm[1][0] + cm[2][0] + cm[3][0] + cm[4][0])\n",
    "print(f\"有人判断为无人的异常概率：{idle_err_count/tmp_test_count:.4f}\")\n",
    "\n",
    "no_idle_err_count  = (cm[0][1] + cm[0][2] + cm[0][3] + cm[0][4])\n",
    "print(f\"无人判断为有人的异常概率：{no_idle_err_count/tmp_test_count:.4f}\")\n",
    "\n",
    "\n",
    "if g_modle_str is 'low':\n",
    "    # 若是低位模型 - 其他类型误识别为站\n",
    "    low_err_count = (cm[0][3] + cm[1][3] + cm[2][3] + cm[4][3])\n",
    "    print(f\"其他类型误识别成站：{ low_err_count/tmp_test_count:.4f}\")\n",
    "\n",
    "if g_modle_str is 'high':\n",
    "    # 若是高位模型 - 其他类型误识别为坐\n",
    "    high_err_count = (cm[0][1] + cm[2][1] + cm[3][1] + cm[4][1])\n",
    "    print(f\"其他类型误识别成坐：{ high_err_count/tmp_test_count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出被错误分类的样本\n",
    "misclassified_samples = [filenames[i] for i in range(len(filenames)) if true_labels[i] != predicted_labels[i]]\n",
    "print(\"被错误分类的样本:\", misclassified_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# 创建目标文件夹\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "target_folder = os.path.join(\"wrongs\", timestamp)\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# 复制被错误分类的样本到目标文件夹\n",
    "for filename in misclassified_samples:\n",
    "    # 假设原始文件位于当前文件夹中\n",
    "    # folder, sample_id = filename.split('_')\n",
    "    source_path = f'{filename}.mp4' # Path('..') / 'data_v2' / folder / f'{sample_id}.mp4'\n",
    "    # target_path = os.path.join(target_folder, os.path.basename(filename))\n",
    "    shutil.copy(source_path, target_folder)\n",
    "\n",
    "print(f\"被错误分类的样本已复制到 {target_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 获取当前日期和时间\n",
    "today = datetime.today()\n",
    "modle_file_name = f'checkpoints/{g_modle_str}/AllData_{today.month}_{today.day}_{g_modle_str}_balanced_{g_modle_extra_str}.pth'\n",
    "print(f'file_name:{modle_file_name}')\n",
    "torch.save(net.state_dict(), modle_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pth_converter import save_params_to_txt\n",
    "\n",
    "# # 使用示例\n",
    "# model_path = 'models\\checkpoints\\low\\AllData_6_11_low_balanced_0d90_3.pth'  # 模型文件路径\n",
    "output_file = f'{modle_file_name[:-3]}txt'  # 输出文件路径\n",
    "save_params_to_txt(modle_file_name, output_file, g_modle_str, op_declares = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
